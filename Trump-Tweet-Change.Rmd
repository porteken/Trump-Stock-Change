---
title: "R Notebook"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{R message=F}
if (Sys.info()[['sysname']]=='Windows')
{
  # update executable path in sys module
  sys <- import("sys")
  exe <- file.path(sys$exec_prefix, "pythonw.exe")
  sys$executable <- exe
  sys$`_base_executable` <- exe
  
  # update executable path in multiprocessing module
  multiprocessing <- import("multiprocessing")
  multiprocessing$set_executable(exe)
}
library(tidyverse)
library(quantmod)
library(rtweet)
library(lubridate)
library(e1071)
library(DT)
library(feasts)
library(caret)
library(tsibble)
library(mlr3verse)
library(mlr3measures)
library(RBERT)
library(data.table)
library(tensorflow)
```

```{R}
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
```

```{R warning=F}
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
```

```{R}
BERT_PRETRAINED_DIR <- RBERT::download_BERT_checkpoint(model = "bert_base_uncased")
BERT_feats <- extract_features(examples = data$text, model='bert_base_uncased',batch_size = 1000L)
data$score<-BERT_feats$output %>% group_by(sequence_index) %>% summarise(score=sqrt(sum(V767^2))) %>% select(score)
```

```{R message=F,tidy=T}
data$date<-date(data$date)
prices<-read.csv('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text')) 
data$is_retweet<-as.numeric(data$is_retweet)-1
train<-data[1:round(nrow(data)*.95-1,0),]
test<-data[round(nrow(data)*.95-1,0):nrow(data),]
data.table(data)
```

```{R warning=F}
lgr::get_logger("mlr3")$set_threshold("warn")
task<-TaskClassif$new('task',train,'change',positive='1')
benchmarks<-benchmark_grid(task,list(lrn('classif.xgboost'),lrn('classif.ranger'),lrn('classif.svm'),lrn('classif.log_reg'),lrn('classif.naive_bayes')),rsmp('cv',folds=10))
future::plan('multiprocess')
bench<-benchmark(benchmarks)
```

```{R}
bench$aggregate() %>% arrange(classif.ce)
```

```{R}
searchspace<-ParamSet$new(list(ParamInt$new('num.trees',lower = 100,upper=1200),ParamInt$new('max.depth',lower=5,upper=30)))
tuner<-AutoTuner$new(lrn('classif.ranger'),rsmp('cv',folds=10),msr('classif.ce'),searchspace,term('evals',n_evals=36),tnr('random_search',batch_size=36))
model<-tuner$train(task)
model$tuning_result
```

```{R}
testing<-TaskClassif$new('test',test,'change',positive='1')
result<-model$predict(testing)
confusion_matrix(result$truth,result$response,positive='1')
```