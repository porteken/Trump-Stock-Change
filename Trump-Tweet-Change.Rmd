---
title: "R Notebook"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{R message=F}
library(reticulate)
if (Sys.info()[['sysname']]=='Windows')
{
  # update executable path in sys module
  sys <- import("sys")
  exe <- file.path(sys$exec_prefix, "pythonw.exe")
  sys$executable <- exe
  sys$`_base_executable` <- exe
  
  # update executable path in multiprocessing module
  multiprocessing <- import("multiprocessing")
  multiprocessing$set_executable(exe)
}
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(DT)
library(feasts)
library(caret)
library(tsibble)
library(mlr3verse)
library(mlr3measures)
```

```{R}
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
```

```{R warning=F}
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
```

```{python}
import numpy as np
import pandas as pd
import torch
from numpy.testing import assert_almost_equal
import re
import spacy
import string
from spacy.tokens import DocBin
import os
from pathlib import Path
from joblib import Parallel, delayed
import thinc.extra.datasets
import plac
import spacy
from spacy.util import minibatch
from functools import partial
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import psutil
import multiprocessing
import csv
file='scores.csv'
if Path(file).is_file():
  os.remove(file)
```

```{python}
from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec
name = "bert-base-uncased"
nlp = TransformersLanguage(trf_name=name, meta={"lang": "en"})
nlp.add_pipe(nlp.create_pipe("sentencizer"))
nlp.add_pipe(TransformersWordPiecer.from_pretrained(nlp.vocab, name))
nlp.add_pipe(TransformersTok2Vec.from_pretrained(nlp.vocab, name))
print(nlp.pipe_names) 
```

```{python}
def transform_texts(nlp,batch_id,texts):
  text=texts
  texts=list(nlp.pipe(texts))
  with open(file,"a") as f:
    headers = ['score', 'text']
    writer = csv.DictWriter(f, delimiter=',', lineterminator='\n',fieldnames=headers)
    file_is_empty = os.stat(file).st_size == 0
    if file_is_empty:
        writer.writeheader()
    for doc in texts:
      writer.writerow({'score':doc.vector_norm,'text':doc.text})
trains=r.data
nlp = spacy.load("en_trf_bertbaseuncased_lg")
partitions = minibatch(trains['text'], size=1000)
multiprocessing.freeze_support()
executor = Parallel(n_jobs=-1,prefer='processes')
do = delayed(partial(transform_texts, nlp))
tasks = (do(i, batch) for i, batch in enumerate(partitions))
executor(tasks)
```

```{python warning=F}
scores=pd.read_csv('scores.csv')
trains=trains.merge(scores,how='inner',on='text')
trains.shape
trains['date']=pd.to_datetime(trains['date'])
print(trains.head())
```

```{R message=F,tidy=T}
data<-py$trains
data$date<-date(data$date)
prices<-read.csv('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text')) 
data$is_retweet<-as.numeric(data$is_retweet)-1
train<-data[1:round(nrow(data)*.95-1,0),]
test<-data[round(nrow(data)*.95-1,0):nrow(data),]
data.table(data)
```

```{R warning=F}
lgr::get_logger("mlr3")$set_threshold("warn")
task<-TaskClassif$new('task',train,'change',positive='1')
benchmarks<-benchmark_grid(task,list(lrn('classif.xgboost'),lrn('classif.ranger'),lrn('classif.svm'),lrn('classif.log_reg'),lrn('classif.naive_bayes')),rsmp('cv',folds=10))
future::plan('multiprocess')
bench<-benchmark(benchmarks)
```

```{R}
bench$aggregate() %>% arrange(classif.ce)
```

```{R}
searchspace<-ParamSet$new(list(ParamInt$new('num.trees',lower = 100,upper=1200),ParamInt$new('max.depth',lower=5,upper=30)))
tuner<-AutoTuner$new(lrn('classif.ranger'),rsmp('cv',folds=10),msr('classif.ce'),searchspace,term('evals',n_evals=36),tnr('random_search',batch_size=36))
model<-tuner$train(task)
model$tuning_result
```

```{R}
testing<-TaskClassif$new('test',test,'change',positive='1')
result<-model$predict(testing)
confusion_matrix(result$truth,result$response,positive='1')
```